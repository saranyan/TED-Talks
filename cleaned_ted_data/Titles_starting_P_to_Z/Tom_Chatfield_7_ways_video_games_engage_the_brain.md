
I love video games.
I&#39;m also slightly in awe of them.
I&#39;m in awe of their power
in terms of imagination, in terms of technology,
in terms of concept.
But I think, above all,
I&#39;m in awe at their power
to motivate, to compel us,
to transfix us,
like really nothing else we&#39;ve ever invented
has quite done before.
And I think that we can learn some pretty amazing things
by looking at how we do this.
And in particular, I think we can learn things
about learning.
Now the video games industry
is far and away the fastest growing
of all modern media.
From about 10 billion in 1990,
it&#39;s worth 50 billion dollars globally today,
and it shows no sign of slowing down.
In four years&#39; time,
it&#39;s estimated it&#39;ll be worth over 80 billion dollars.
That&#39;s about three times the recorded music industry.
This is pretty stunning,
but I don&#39;t think it&#39;s the most telling statistic of all.
The thing that really amazes me
is that, today,
people spend about
eight billion real dollars a year
buying virtual items
that only exist
inside video games.
This is a screenshot from the virtual game world, Entropia Universe.
Earlier this year,
a virtual asteroid in it
sold for 330,000 real dollars.
And this
is a Titan class ship
in the space game, EVE Online.
And this virtual object
takes 200 real people
about 56 days of real time to build,
plus countless thousands of hours
of effort before that.
And yet, many of these get built.
At the other end of the scale,
the game Farmville that you may well have heard of,
has 70 million players
around the world
and most of these players
are playing it almost every day.
This may all sound
really quite alarming to some people,
an index of something worrying
or wrong in society.
But we&#39;re here for the good news,
and the good news is
that I think we can explore
why this very real human effort,
this very intense generation of value, is occurring.
And by answering that question,
I think we can take something
extremely powerful away.
And I think the most interesting way
to think about how all this is going on
is in terms of rewards.
And specifically, it&#39;s in terms
of the very intense emotional rewards
that playing games offers to people
both individually
and collectively.
Now if we look at what&#39;s going on in someone&#39;s head
when they are being engaged,
two quite different processes are occurring.
On the one hand, there&#39;s the wanting processes.
This is a bit like ambition and drive -- I&#39;m going to do that. I&#39;m going to work hard.
On the other hand, there&#39;s the liking processes,
fun and affection
and delight
and an enormous flying beast with an orc on the back.
It&#39;s a really great image. It&#39;s pretty cool.
It&#39;s from the game World of Warcraft with more than 10 million players globally,
one of whom is me, another of whom is my wife.
And this kind of a world,
this vast flying beast you can ride around,
shows why games are so very good
at doing both the wanting and the liking.
Because it&#39;s very powerful. It&#39;s pretty awesome.
It gives you great powers.
Your ambition is satisfied, but it&#39;s very beautiful.
It&#39;s a very great pleasure to fly around.
And so these combine to form
a very intense emotional engagement.
But this isn&#39;t the really interesting stuff.
The really interesting stuff about virtuality
is what you can measure with it.
Because what you can measure in virtuality
is everything.
Every single thing that every single person
who&#39;s ever played in a game has ever done can be measured.
The biggest games in the world today
are measuring more than one billion points of data
about their players, about what everybody does --
far more detail than you&#39;d ever get from any website.
And this allows something very special
to happen in games.
It&#39;s something called the reward schedule.
And by this, I mean looking
at what millions upon millions of people have done
and carefully calibrating the rate,
the nature, the type, the intensity of rewards in games
to keep them engaged
over staggering amounts of time and effort.
Now, to try and explain this
in sort of real terms,
I want to talk about a kind of task
that might fall to you in so many games.
Go and get a certain amount of a certain little game-y item.
Let&#39;s say, for the sake of argument,
my mission is to get 15 pies
and I can get 15 pies
by killing these cute, little monsters.
Simple game quest.
Now you can think about this, if you like,
as a problem about boxes.
I&#39;ve got to keep opening boxes.
I don&#39;t know what&#39;s inside them until I open them.
And I go around opening box after box until I&#39;ve got 15 pies.
Now, if you take a game like Warcraft,
you can think about it, if you like,
as a great box-opening effort.
The game&#39;s just trying to get people to open about a million boxes,
getting better and better stuff in them.
This sounds immensely boring
but games are able
to make this process
incredibly compelling.
And the way they do this
is through a combination of probability and data.
Let&#39;s think about probability.
If we want to engage someone
in the process of opening boxes to try and find pies,
we want to make sure it&#39;s neither too easy,
nor too difficult, to find a pie.
So what do you do? Well, you look at a million people --
no, 100 million people, 100 million box openers --
and you work out, if you make the pie rate
about 25 percent --
that&#39;s neither too frustrating, nor too easy.
It keeps people engaged.
But of course, that&#39;s not all you do -- there&#39;s 15 pies.
Now, I could make a game called Piecraft,
where all you had to do was get a million pies
or a thousand pies.
That would be very boring.
Fifteen is a pretty optimal number.
You find that -- you know, between five and 20
is about the right number for keeping people going.
But we don&#39;t just have pies in the boxes.
There&#39;s 100 percent up here.
And what we do is make sure that every time a box is opened,
there&#39;s something in it, some little reward
that keeps people progressing and engaged.
In most adventure games,
it&#39;s a little bit in-game currency, a little bit experience.
But we don&#39;t just do that either.
We also say there&#39;s going to be loads of other items
of varying qualities and levels of excitement.
There&#39;s going to be a 10 percent chance you get a pretty good item.
There&#39;s going to be a 0.1 percent chance
you get an absolutely awesome item.
And each of these rewards is carefully calibrated to the item.
And also, we say,
&quot;Well, how many monsters? Should I have the entire world full of a billion monsters?&quot;
No, we want one or two monsters on the screen at any one time.
So I&#39;m drawn on. It&#39;s not too easy, not too difficult.
So all this is very powerful.
But we&#39;re in virtuality. These aren&#39;t real boxes.
So we can do
some rather amazing things.
We notice, looking at all these people opening boxes,
that when people get to about 13 out of 15 pies,
their perception shifts, they start to get a bit bored, a bit testy.
They&#39;re not rational about probability.
They think this game is unfair.
It&#39;s not giving me my last two pies. I&#39;m going to give up.
If they&#39;re real boxes, there&#39;s not much we can do,
but in a game we can just say, &quot;Right, well.
When you get to 13 pies, you&#39;ve got 75 percent chance of getting a pie now.&quot;
Keep you engaged. Look at what people do --
adjust the world to match their expectation.
Our games don&#39;t always do this.
And one thing they certainly do at the moment
is if you got a 0.1 percent awesome item,
they make very sure another one doesn&#39;t appear for a certain length of time
to keep the value, to keep it special.
And the point is really
that we evolved to be satisfied by the world
in particular ways.
Over tens and hundreds of thousands of years,
we evolved to find certain things stimulating,
and as very intelligent, civilized beings,
we&#39;re enormously stimulated by problem solving and learning.
But now, we can reverse engineer that
and build worlds
that expressly tick our evolutionary boxes.
So what does all this mean in practice?
Well, I&#39;ve come up
with seven things
that, I think, show
how you can take these lessons from games
and use them outside of games.

The first one is very simple:
experience bars measuring progress --
something that&#39;s been talked about brilliantly
by people like Jesse Schell earlier this year.
It&#39;s already been done at the University of Indiana in the States, among other places.
It&#39;s the simple idea that instead of grading people incrementally
in little bits and pieces,
you give them one profile character avatar
which is constantly progressing
in tiny, tiny, tiny little increments which they feel are their own.
And everything comes towards that,
and they watch it creeping up, and they own that as it goes along.
Second, multiple long and short-term aims --
5,000 pies, boring,
15 pies, interesting.
So, you give people
lots and lots of different tasks.
You say, it&#39;s about
doing 10 of these questions,
but another task
is turning up to 20 classes on time,
but another task is collaborating with other people,
another task is showing you&#39;re working five times,
another task is hitting this particular target.
You break things down into these calibrated slices
that people can choose and do in parallel
to keep them engaged
and that you can use to point them
towards individually beneficial activities.
Third, you reward effort.
It&#39;s your 100 percent factor. Games are brilliant at this.
Every time you do something, you get credit; you get a credit for trying.
You don&#39;t punish failure. You reward every little bit of effort --
a little bit of gold, a little bit of credit. You&#39;ve done 20 questions -- tick.
It all feeds in as minute reinforcement.
Fourth, feedback.
This is absolutely crucial,
and virtuality is dazzling at delivering this.
If you look at some of the most intractable problems in the world today
that we&#39;ve been hearing amazing things about,
it&#39;s very, very hard for people to learn
if they cannot link consequences to actions.
Pollution, global warming, these things --
the consequences are distant in time and space.
It&#39;s very hard to learn, to feel a lesson.
But if you can model things for people,
if you can give things to people that they can manipulate
and play with and where the feedback comes,
then they can learn a lesson, they can see,
they can move on, they can understand.
And fifth,
the element of uncertainty.
Now this is the neurological goldmine,
if you like,
because a known reward
excites people,
but what really gets them going
is the uncertain reward,
the reward pitched at the right level of uncertainty,
that they didn&#39;t quite know whether they were going to get it or not.
The 25 percent. This lights the brain up.
And if you think about
using this in testing,
in just introducing control elements of randomness
in all forms of testing and training,
you can transform the levels of people&#39;s engagement
by tapping into this very powerful
evolutionary mechanism.
When we don&#39;t quite predict something perfectly,
we get really excited about it.
We just want to go back and find out more.
As you probably know, the neurotransmitter
associated with learning is called dopamine.
It&#39;s associated with reward-seeking behavior.
And something very exciting is just beginning to happen
in places like the University of Bristol in the U.K.,
where we are beginning to be able to model mathematically
dopamine levels in the brain.
And what this means is we can predict learning,
we can predict enhanced engagement,
these windows, these windows of time,
in which the learning is taking place at an enhanced level.
And two things really flow from this.
The first has to do with memory,
that we can find these moments.
When someone is more likely to remember,
we can give them a nugget in a window.
And the second thing is confidence,
that we can see how game-playing and reward structures
make people braver, make them more willing to take risks,
more willing to take on difficulty,
harder to discourage.
This can all seem very sinister.
But you know, sort of &quot;our brains have been manipulated; we&#39;re all addicts.&quot;
The word &quot;addiction&quot; is thrown around.
There are real concerns there.
But the biggest neurological turn-on for people
is other people.
This is what really excites us.
In reward terms, it&#39;s not money;
it&#39;s not being given cash -- that&#39;s nice --
it&#39;s doing stuff with our peers,
watching us, collaborating with us.
And I want to tell you a quick story about 1999 --
a video game called EverQuest.
And in this video game,
there were two really big dragons, and you had to team up to kill them --
42 people, up to 42 to kill these big dragons.
That&#39;s a problem
because they dropped two or three decent items.
So players addressed this problem
by spontaneously coming up with a system
to motivate each other,
fairly and transparently.
What happened was, they paid each other a virtual currency
they called &quot;dragon kill points.&quot;
And every time you turned up to go on a mission,
you got paid in dragon kill points.
They tracked these on a separate website.
So they tracked their own private currency,
and then players could bid afterwards
for cool items they wanted --
all organized by the players themselves.
Now the staggering system, not just that this worked in EverQuest,
but that today, a decade on,
every single video game in the world with this kind of task
uses a version of this system --
tens of millions of people.
And the success rate
is at close to 100 percent.
This is a player-developed,
self-enforcing, voluntary currency,
and it&#39;s incredibly sophisticated
player behavior.
And I just want to end by suggesting
a few ways in which these principles
could fan out into the world.
Let&#39;s start with business.
I mean, we&#39;re beginning to see some of the big problems
around something like business are
recycling and energy conservation.
We&#39;re beginning to see the emergence of wonderful technologies
like real-time energy meters.
And I just look at this, and I think, yes,
we could take that so much further
by allowing people to set targets
by setting calibrated targets,
by using elements of uncertainty,
by using these multiple targets,
by using a grand, underlying reward and incentive system,
by setting people up
to collaborate in terms of groups, in terms of streets
to collaborate and compete,
to use these very sophisticated
group and motivational mechanics we see.
In terms of education,
perhaps most obviously of all,
we can transform how we engage people.
We can offer people the grand continuity
of experience and personal investment.
We can break things down
into highly calibrated small tasks.
We can use calculated randomness.
We can reward effort consistently
as everything fields together.
And we can use the kind of group behaviors
that we see evolving when people are at play together,
these really quite unprecedentedly complex
cooperative mechanisms.
Government, well, one thing that comes to mind
is the U.S. government, among others,
is literally starting to pay people
to lose weight.
So we&#39;re seeing financial reward being used
to tackle the great issue of obesity.
But again, those rewards
could be calibrated so precisely
if we were able to use the vast expertise
of gaming systems to just jack up that appeal,
to take the data, to take the observations,
of millions of human hours
and plow that feedback
into increasing engagement.
And in the end, it&#39;s this word, &quot;engagement,&quot;
that I want to leave you with.
It&#39;s about how individual engagement
can be transformed
by the psychological and the neurological lessons
we can learn from watching people that are playing games.
But it&#39;s also about collective engagement
and about the unprecedented laboratory
for observing what makes people tick
and work and play and engage
on a grand scale in games.
And if we can look at these things and learn from them
and see how to turn them outwards,
then I really think we have something quite revolutionary on our hands.
Thank you very much.

(Applause)

